{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6060fdb",
   "metadata": {},
   "source": [
    "# Hyperparameter search for Movielens VAE\n",
    "\n",
    "This is the ipynb I will use to actually look for the best configuration of the model and its hyperparameters\n",
    "\n",
    "\n",
    "## Input info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b240580c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leuch\\AppData\\Local\\Temp\\ipykernel_15660\\3502759811.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support sep=None with delim_whitespace=False; you can avoid this warning by specifying engine='python'.\n",
      "  raw_data = pd.read_csv(\"./data/Movielens100/u.data\", sep = None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 1., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [2., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 2., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "raw_data = pd.read_csv(\"./data/Movielens100/u.data\", sep = None, names=[\"userId\", \"movieId\", \"rating\", \"timestamp\"])\n",
    "raw_data = raw_data.loc[:, raw_data.columns != \"timestamp\"]\n",
    "#make indices start at 0\n",
    "raw_data[\"userId\"] -= 1\n",
    "raw_data[\"movieId\"] -= 1\n",
    "#make ratings center around 0\n",
    "raw_data[\"rating\"] -= 3\n",
    "\n",
    "# create (943, 1682) matrix of user ratings per movie\n",
    "user_ratings = pd.DataFrame(np.zeros((943,1682)))\n",
    "for i in raw_data.index:\n",
    "    user_ratings[raw_data[\"movieId\"][i]][raw_data[\"userId\"][i]] = raw_data[\"rating\"][i]\n",
    "user_ratings = user_ratings.to_numpy()    \n",
    "user_ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787e5685",
   "metadata": {},
   "source": [
    "## Begin model and tuning of Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "af32e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn \n",
    "import torch\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "device = \"cuda\"\n",
    "\n",
    "class MovielensDataset(Dataset):\n",
    "    def __init__(self, data, mask_magnitude):\n",
    "        self.data = data\n",
    "        # create a mask of 0 and 1 values where half are 0 and half are 1. \n",
    "        #The ratio of masked values is something that can and should be optimized. \n",
    "        self.random_mask = np.clip((np.random.randn(1682) + mask_magnitude).round(), a_max = 1, a_min = 0)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        np.random.shuffle(self.random_mask)\n",
    "        return self.data[idx] * self.random_mask, self.data[idx]\n",
    "\n",
    "\n",
    "class VariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            #Encoder\n",
    "            nn.Linear(1682, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            #Decoder\n",
    "            nn.Linear(512,1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024,1682),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # distribution parameters\n",
    "        self.fc_mu = nn.Linear(1024, 512)\n",
    "        self.fc_var = nn.Linear(1024, 512)\n",
    "        self.f1 = 0.0\n",
    "        # for the gaussian likelihood\n",
    "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
    "        \n",
    "        \n",
    "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
    "        scale = torch.exp(logscale)\n",
    "        mean = x_hat\n",
    "        dist = torch.distributions.Normal(mean, scale)\n",
    "\n",
    "        # measure prob of seeing data under p(x|z)\n",
    "        log_pxz = dist.log_prob(x)\n",
    "        return log_pxz.sum(dim=1)\n",
    "    \n",
    "    def kl_divergence(self, z, mu, std):\n",
    "        # --------------------------\n",
    "        # Monte carlo KL divergence\n",
    "        # --------------------------\n",
    "        # 1. define the first two probabilities (in this case Normal for both)\n",
    "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
    "        q = torch.distributions.Normal(mu, std)\n",
    "\n",
    "        # 2. get the probabilities from the equation\n",
    "        log_qzx = q.log_prob(z)\n",
    "        log_pz = p.log_prob(z)\n",
    "\n",
    "        # kl\n",
    "        kl = (log_qzx - log_pz)\n",
    "        kl = kl.sum(-1)\n",
    "        return kl\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # encode x to get the mu and variance parameters\n",
    "        x_encoded = self.encoder(x)\n",
    "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
    "\n",
    "        # sample z from q\n",
    "        std = torch.exp(log_var / 2)\n",
    "        \n",
    "        #perform the kernel trick to allow for backprop through sampling\n",
    "        \n",
    "        epsilon = torch.distributions.Normal(0, 1).rsample()\n",
    "        z = mu + epsilon * std\n",
    "        # decoded\n",
    "        ratings = self.decoder(z) * 2\n",
    "        return ratings, z, mu, std\n",
    "    \n",
    "    def vae_loss(self, x_hat, x, z, mu, std):\n",
    "        # reconstruction loss\n",
    "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
    "    \n",
    "        # kl\n",
    "        kl = self.kl_divergence(z, mu, std)\n",
    "\n",
    "        # elbo\n",
    "        elbo = (kl - recon_loss)\n",
    "        elbo = elbo.mean()\n",
    "\n",
    "        return elbo\n",
    "def get_precision_and_recall(labels, predictions):\n",
    "    relevance_labels = labels > 0.5\n",
    "    \n",
    "    #To evaluate for comparison to other papers we mask by setting 20% of labels to false \n",
    "    \n",
    "    pred_relevance = predictions > 0.5\n",
    "    \n",
    "    precision_recall_fscore_support(relevance_labels.flatten().cpu(), pred_relevance.flatten().cpu(), average=\"binary\")\n",
    "\n",
    "def train(dataloader, model,  optimizer, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "        \n",
    "        #compute prediction error\n",
    "        pred, z, mu, std = model(X)\n",
    "        loss = model.vae_loss(pred, y, z, mu, std)\n",
    "        mse_loss = mse_loss_fcn(pred, y)\n",
    "        \n",
    "        #Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0 and batch % 64 == 0:\n",
    "            loss , current = loss.item(), (batch+1) * len(X)\n",
    "            print(\"Epoch : \" + str(epoch))\n",
    "            print(f\"loss: {loss:>7f}\")\n",
    "            print(f\"MSE loss: {mse_loss:>7f}\")\n",
    "            losses.append(loss)\n",
    "            mse_losses.append(mse_loss.item())\n",
    "\n",
    "def test(dataloader, model, epoch):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches= len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct, test_mse_loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device).to(torch.float32), y.to(device).to(torch.float32)\n",
    "            \n",
    "            \n",
    "            pred, z, mu, std = model(X)\n",
    "            test_loss += model.vae_loss(pred, y, z, mu, std).item()\n",
    "            test_mse_loss += mse_loss_fcn(pred, y)\n",
    "    test_loss /= num_batches\n",
    "    test_mse_loss /= num_batches\n",
    "    if epoch % 100 ==0:\n",
    "        test_losses.append(test_loss)\n",
    "        #Come back and actually do the accuracy where it sees if it's at least on the right side of it or compute precision/recall or something like that\n",
    "        print(f\"Test Error: \\n Avg Loss : {test_loss:>8f} \")\n",
    "        print(f\" MSE loss: {test_mse_loss:>7f}\")\n",
    "        test_mse_losses.append(test_mse_loss.item())\n",
    "        \n",
    "        #compute precision and recall\n",
    "        relevance_labels = y > 0\n",
    "        pred_relevance = pred > 0.5\n",
    "        model.f1 = precision_recall_fscore_support(relevance_labels.flatten().cpu(), pred_relevance.flatten().cpu(), average=\"binary\")\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56869152",
   "metadata": {},
   "source": [
    "## The actual search \n",
    "The following contains all of the logic you need to do to restart everything over so long as you've already loaded the ones above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb1c5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0\n",
      "loss: 1794.213989\n",
      "MSE loss: 0.295352\n",
      "Test Error: \n",
      " Avg Loss : 1635.590332 \n",
      " MSE loss: 0.099956\n",
      " F1 Score: (0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leuch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100\n",
      "loss: 1404.353027\n",
      "MSE loss: 0.077986\n",
      "Test Error: \n",
      " Avg Loss : 1424.222412 \n",
      " MSE loss: 0.080196\n",
      " F1 Score: (0.5707348656523147, 0.2857837574971632, 0.3808597969323828, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 200\n",
      "loss: 1164.096680\n",
      "MSE loss: 0.058970\n",
      "Test Error: \n",
      " Avg Loss : 1188.011353 \n",
      " MSE loss: 0.074344\n",
      " F1 Score: (0.627349319507453, 0.31382720051872265, 0.4183684494867639, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 300\n",
      "loss: 904.481812\n",
      "MSE loss: 0.045473\n",
      "Test Error: \n",
      " Avg Loss : 996.119995 \n",
      " MSE loss: 0.072100\n",
      " F1 Score: (0.6593198992443325, 0.3394391311395688, 0.4481540930979133, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 400\n",
      "loss: 712.950134\n",
      "MSE loss: 0.034307\n",
      "Test Error: \n",
      " Avg Loss : 800.585144 \n",
      " MSE loss: 0.070057\n",
      " F1 Score: (0.6704275534441805, 0.3660236667207003, 0.4735241690258991, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 500\n",
      "loss: 404.868042\n",
      "MSE loss: 0.033360\n",
      "Test Error: \n",
      " Avg Loss : 677.315063 \n",
      " MSE loss: 0.073040\n",
      " F1 Score: (0.7497761862130707, 0.2715188847463122, 0.3986671426871356, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 186.028015\n",
      "MSE loss: 0.023975\n",
      "Test Error: \n",
      " Avg Loss : 486.357971 \n",
      " MSE loss: 0.069047\n",
      " F1 Score: (0.7067881835323696, 0.3645647592802723, 0.4810180729333761, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 700\n",
      "loss: 33.809914\n",
      "MSE loss: 0.013996\n",
      "Test Error: \n",
      " Avg Loss : 374.708984 \n",
      " MSE loss: 0.069909\n",
      " F1 Score: (0.6317153628652215, 0.43459231642081375, 0.5149332565062903, None)\n",
      "\n",
      "New best using hyper parameters : 1.3 ,0.0 ,0.0\n",
      "Epoch : 800\n",
      "loss: -344.218506\n",
      "MSE loss: 0.019162\n",
      "Test Error: \n",
      " Avg Loss : 228.133591 \n",
      " MSE loss: 0.069969\n",
      " F1 Score: (0.7150343924009172, 0.35386610471713403, 0.47343309477336804, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -406.840942\n",
      "MSE loss: 0.011992\n",
      "Test Error: \n",
      " Avg Loss : 145.968445 \n",
      " MSE loss: 0.070328\n",
      " F1 Score: (0.6570397111913358, 0.413032906467823, 0.5072160844033046, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -659.769470\n",
      "MSE loss: 0.007200\n",
      "Test Error: \n",
      " Avg Loss : 168.643433 \n",
      " MSE loss: 0.068936\n",
      " F1 Score: (0.6794202898550724, 0.3799643378181229, 0.4873687493502443, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -917.122986\n",
      "MSE loss: 0.006191\n",
      "Test Error: \n",
      " Avg Loss : 261.718536 \n",
      " MSE loss: 0.069551\n",
      " F1 Score: (0.6693249786385645, 0.38093694277840817, 0.48553719008264457, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -1078.250122\n",
      "MSE loss: 0.005124\n",
      "Test Error: \n",
      " Avg Loss : 399.553375 \n",
      " MSE loss: 0.069410\n",
      " F1 Score: (0.6673092811897549, 0.39277030312854594, 0.4944897959183673, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -1276.032471\n",
      "MSE loss: 0.004237\n",
      "Test Error: \n",
      " Avg Loss : 676.730164 \n",
      " MSE loss: 0.069653\n",
      " F1 Score: (0.6594222833562586, 0.38855568163397636, 0.48898408812729505, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -1531.691406\n",
      "MSE loss: 0.004943\n",
      "Test Error: \n",
      " Avg Loss : 1093.653809 \n",
      " MSE loss: 0.069572\n",
      " F1 Score: (0.6316443119721808, 0.4122224023342519, 0.4988719960765082, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -1692.218018\n",
      "MSE loss: 0.002776\n",
      "Test Error: \n",
      " Avg Loss : 1738.810791 \n",
      " MSE loss: 0.070107\n",
      " F1 Score: (0.6474987106756059, 0.40703517587939697, 0.4998507017020006, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -1891.560913\n",
      "MSE loss: 0.002494\n",
      "Test Error: \n",
      " Avg Loss : 2601.895996 \n",
      " MSE loss: 0.070203\n",
      " F1 Score: (0.6354922279792746, 0.39763332792997247, 0.48918137401535544, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -2212.312012\n",
      "MSE loss: 0.003462\n",
      "Test Error: \n",
      " Avg Loss : 3677.131104 \n",
      " MSE loss: 0.071838\n",
      " F1 Score: (0.5914413455397062, 0.4503160966120927, 0.51131971286582, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -2276.695312\n",
      "MSE loss: 0.002301\n",
      "Test Error: \n",
      " Avg Loss : 4909.175781 \n",
      " MSE loss: 0.070690\n",
      " F1 Score: (0.6274131274131274, 0.42146214945696225, 0.504217977310191, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -2321.887695\n",
      "MSE loss: 0.001761\n",
      "Test Error: \n",
      " Avg Loss : 6471.548828 \n",
      " MSE loss: 0.071120\n",
      " F1 Score: (0.6243781094527363, 0.4068730750526828, 0.49268819314947493, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1661.182129\n",
      "MSE loss: 0.137109\n",
      "Test Error: \n",
      " Avg Loss : 1652.376831 \n",
      " MSE loss: 0.113735\n",
      " F1 Score: (0.0, 0.0, 0.0, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1384.317749\n",
      "MSE loss: 0.070068\n",
      "Test Error: \n",
      " Avg Loss : 1417.666260 \n",
      " MSE loss: 0.079064\n",
      " F1 Score: (0.5900455927051672, 0.25174258388717785, 0.35291444154073404, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1202.730347\n",
      "MSE loss: 0.079826\n",
      "Test Error: \n",
      " Avg Loss : 1204.076172 \n",
      " MSE loss: 0.079263\n",
      " F1 Score: (0.6362893338782182, 0.2523909871940347, 0.36142061281337046, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 1002.621216\n",
      "MSE loss: 0.071929\n",
      "Test Error: \n",
      " Avg Loss : 1023.819641 \n",
      " MSE loss: 0.099058\n",
      " F1 Score: (0.47839149526230645, 0.3355487112984276, 0.3944359756097561, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 748.509644\n",
      "MSE loss: 0.044127\n",
      "Test Error: \n",
      " Avg Loss : 802.961243 \n",
      " MSE loss: 0.072247\n",
      " F1 Score: (0.6815263908701854, 0.30977467985086726, 0.42594450016716817, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 519.159546\n",
      "MSE loss: 0.034940\n",
      "Test Error: \n",
      " Avg Loss : 629.134949 \n",
      " MSE loss: 0.071523\n",
      " F1 Score: (0.7025641025641025, 0.31090938563786674, 0.43105966962580056, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 331.388916\n",
      "MSE loss: 0.032692\n",
      "Test Error: \n",
      " Avg Loss : 466.514374 \n",
      " MSE loss: 0.074156\n",
      " F1 Score: (0.7434086629001884, 0.25595720538174743, 0.38080308694079346, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 67.977356\n",
      "MSE loss: 0.022396\n",
      "Test Error: \n",
      " Avg Loss : 338.594055 \n",
      " MSE loss: 0.072461\n",
      " F1 Score: (0.7675700505282499, 0.27087048143945536, 0.40043134435657807, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: -117.657822\n",
      "MSE loss: 0.021065\n",
      "Test Error: \n",
      " Avg Loss : 265.082855 \n",
      " MSE loss: 0.073252\n",
      " F1 Score: (0.7718422366450325, 0.2506078781001783, 0.37836514929025944, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -332.475403\n",
      "MSE loss: 0.019214\n",
      "Test Error: \n",
      " Avg Loss : 1872.053711 \n",
      " MSE loss: 0.241111\n",
      " F1 Score: (0.1571832276789124, 0.6672070027557141, 0.25442744552619384, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -522.666016\n",
      "MSE loss: 0.016820\n",
      "Test Error: \n",
      " Avg Loss : 217.219910 \n",
      " MSE loss: 0.073880\n",
      " F1 Score: (0.7934604904632152, 0.23601880369589884, 0.3638180909545227, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -661.087402\n",
      "MSE loss: 0.016125\n",
      "Test Error: \n",
      " Avg Loss : 302.053192 \n",
      " MSE loss: 0.074374\n",
      " F1 Score: (0.7868852459016393, 0.225644350786189, 0.3507180650037793, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -826.648071\n",
      "MSE loss: 0.014772\n",
      "Test Error: \n",
      " Avg Loss : 428.592896 \n",
      " MSE loss: 0.073277\n",
      " F1 Score: (0.7664233576642335, 0.2553088020748906, 0.38302529182879375, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -961.631714\n",
      "MSE loss: 0.014335\n",
      "Test Error: \n",
      " Avg Loss : 671.212158 \n",
      " MSE loss: 0.073650\n",
      " F1 Score: (0.772452068617558, 0.24817636569946508, 0.37565942829100724, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -1054.105469\n",
      "MSE loss: 0.013392\n",
      "Test Error: \n",
      " Avg Loss : 1032.441284 \n",
      " MSE loss: 0.074302\n",
      " F1 Score: (0.7637040979244278, 0.23261468633490032, 0.356610337972167, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -1176.663086\n",
      "MSE loss: 0.011682\n",
      "Test Error: \n",
      " Avg Loss : 1349.349976 \n",
      " MSE loss: 0.073083\n",
      " F1 Score: (0.7518281535648994, 0.2666558599448857, 0.3936819432810817, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -1210.770874\n",
      "MSE loss: 0.012057\n",
      "Test Error: \n",
      " Avg Loss : 1807.640259 \n",
      " MSE loss: 0.072553\n",
      " F1 Score: (0.7258947368421053, 0.2794618252553088, 0.40355805243445697, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -1171.620850\n",
      "MSE loss: 0.012424\n",
      "Test Error: \n",
      " Avg Loss : 2186.653320 \n",
      " MSE loss: 0.073482\n",
      " F1 Score: (0.691160014919806, 0.3003728319014427, 0.4187570621468927, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -1337.883667\n",
      "MSE loss: 0.012882\n",
      "Test Error: \n",
      " Avg Loss : 2472.827881 \n",
      " MSE loss: 0.072891\n",
      " F1 Score: (0.730379746835443, 0.2805965310423083, 0.4054338915563883, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -883.427246\n",
      "MSE loss: 0.019703\n",
      "Test Error: \n",
      " Avg Loss : 4096.102539 \n",
      " MSE loss: 0.095226\n",
      " F1 Score: (0.3695779258739624, 0.5124007132436376, 0.4294253498166011, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1637.698608\n",
      "MSE loss: 0.109452\n",
      "Test Error: \n",
      " Avg Loss : 1643.091553 \n",
      " MSE loss: 0.120545\n",
      " F1 Score: (0.14794861168669707, 0.057869995136975196, 0.0831973898858075, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1411.753418\n",
      "MSE loss: 0.080274\n",
      "Test Error: \n",
      " Avg Loss : 1408.228394 \n",
      " MSE loss: 0.079544\n",
      " F1 Score: (0.5688976377952756, 0.28108283352245095, 0.3762612563740913, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1175.746338\n",
      "MSE loss: 0.072253\n",
      "Test Error: \n",
      " Avg Loss : 1182.417358 \n",
      " MSE loss: 0.077065\n",
      " F1 Score: (0.621668397369332, 0.2911330847787324, 0.3965555310223008, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 929.673462\n",
      "MSE loss: 0.063579\n",
      "Test Error: \n",
      " Avg Loss : 995.518738 \n",
      " MSE loss: 0.086576\n",
      " F1 Score: (0.4848297213622291, 0.380774841951694, 0.42654802978027967, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 400\n",
      "loss: 747.882324\n",
      "MSE loss: 0.046658\n",
      "Test Error: \n",
      " Avg Loss : 804.863281 \n",
      " MSE loss: 0.074972\n",
      " F1 Score: (0.6963053187170117, 0.27800291781488085, 0.3973586654309546, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 546.911987\n",
      "MSE loss: 0.040373\n",
      "Test Error: \n",
      " Avg Loss : 650.266052 \n",
      " MSE loss: 0.077613\n",
      " F1 Score: (0.6335078534031413, 0.2942130004863025, 0.4018153641797653, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 312.975891\n",
      "MSE loss: 0.033687\n",
      "Test Error: \n",
      " Avg Loss : 535.353516 \n",
      " MSE loss: 0.086998\n",
      " F1 Score: (0.7104984093319194, 0.10860755389852489, 0.18841394825646796, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 83.139427\n",
      "MSE loss: 0.028836\n",
      "Test Error: \n",
      " Avg Loss : 355.680847 \n",
      " MSE loss: 0.073949\n",
      " F1 Score: (0.7622133599202393, 0.24785216404603663, 0.3740672782874618, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: -87.972610\n",
      "MSE loss: 0.026279\n",
      "Test Error: \n",
      " Avg Loss : 282.899384 \n",
      " MSE loss: 0.074340\n",
      " F1 Score: (0.7610574478901881, 0.2426649375911817, 0.3679941002949852, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -223.077591\n",
      "MSE loss: 0.024642\n",
      "Test Error: \n",
      " Avg Loss : 246.241043 \n",
      " MSE loss: 0.075345\n",
      " F1 Score: (0.7910447761194029, 0.2147835953963365, 0.33783783783783783, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -305.579041\n",
      "MSE loss: 0.035114\n",
      "Test Error: \n",
      " Avg Loss : 2811.375488 \n",
      " MSE loss: 0.276425\n",
      " F1 Score: (0.14874854964362672, 0.7273464094666883, 0.24698629382947102, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -745.764343\n",
      "MSE loss: 0.028449\n",
      "Test Error: \n",
      " Avg Loss : 238.236542 \n",
      " MSE loss: 0.076318\n",
      " F1 Score: (0.7670068027210885, 0.21932241854433457, 0.3411067691919829, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -600.241211\n",
      "MSE loss: 0.026869\n",
      "Test Error: \n",
      " Avg Loss : 475.314056 \n",
      " MSE loss: 0.075670\n",
      " F1 Score: (0.7662337662337663, 0.21997082185119143, 0.34181360201511335, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -798.500000\n",
      "MSE loss: 0.019180\n",
      "Test Error: \n",
      " Avg Loss : 612.339417 \n",
      " MSE loss: 0.073970\n",
      " F1 Score: (0.7455048409405256, 0.26211703679688764, 0.387862796833773, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -787.989136\n",
      "MSE loss: 0.019697\n",
      "Test Error: \n",
      " Avg Loss : 884.184265 \n",
      " MSE loss: 0.073445\n",
      " F1 Score: (0.7360861759425493, 0.26584535581131463, 0.39061569608193397, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -932.767517\n",
      "MSE loss: 0.017808\n",
      "Test Error: \n",
      " Avg Loss : 1147.764648 \n",
      " MSE loss: 0.074238\n",
      " F1 Score: (0.747029702970297, 0.2446101475117523, 0.3685431676639394, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -945.188232\n",
      "MSE loss: 0.017154\n",
      "Test Error: \n",
      " Avg Loss : 1359.292358 \n",
      " MSE loss: 0.073147\n",
      " F1 Score: (0.7128753599341835, 0.28092073269573675, 0.4030232558139535, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -760.072083\n",
      "MSE loss: 0.021015\n",
      "Test Error: \n",
      " Avg Loss : 2442.960938 \n",
      " MSE loss: 0.100664\n",
      " F1 Score: (0.35773889636608347, 0.43086399740638676, 0.39091109640414734, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -971.319580\n",
      "MSE loss: 0.019362\n",
      "Test Error: \n",
      " Avg Loss : 1504.052002 \n",
      " MSE loss: 0.071985\n",
      " F1 Score: (0.6712884680419344, 0.3217701410277192, 0.43502081963620426, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -1046.255127\n",
      "MSE loss: 0.016305\n",
      "Test Error: \n",
      " Avg Loss : 1638.645630 \n",
      " MSE loss: 0.073242\n",
      " F1 Score: (0.6666666666666666, 0.29988652942130006, 0.41368515205724504, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1924.905884\n",
      "MSE loss: 0.450330\n",
      "Test Error: \n",
      " Avg Loss : 1661.828369 \n",
      " MSE loss: 0.125997\n",
      " F1 Score: (0.04139433551198257, 0.009239747122710326, 0.015107341637953882, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1402.551025\n",
      "MSE loss: 0.092347\n",
      "Test Error: \n",
      " Avg Loss : 1378.541016 \n",
      " MSE loss: 0.084512\n",
      " F1 Score: (0.6440879382055853, 0.1757172961582104, 0.2761079979623026, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1206.900879\n",
      "MSE loss: 0.098113\n",
      "Test Error: \n",
      " Avg Loss : 1206.452515 \n",
      " MSE loss: 0.078205\n",
      " F1 Score: (0.5868883312421581, 0.3032906467822986, 0.39991450251148875, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 1613.623291\n",
      "MSE loss: 0.057593\n",
      "Test Error: \n",
      " Avg Loss : 942.393250 \n",
      " MSE loss: 0.075928\n",
      " F1 Score: (0.6569952305246423, 0.26795266655859945, 0.38065630397236616, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 743.623474\n",
      "MSE loss: 0.048556\n",
      "Test Error: \n",
      " Avg Loss : 806.196533 \n",
      " MSE loss: 0.074878\n",
      " F1 Score: (0.6852706672261855, 0.2647106500243151, 0.38189897100093545, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 467.642029\n",
      "MSE loss: 0.049179\n",
      "Test Error: \n",
      " Avg Loss : 641.181213 \n",
      " MSE loss: 0.075053\n",
      " F1 Score: (0.7129586623316303, 0.24882476900632194, 0.368901706320596, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 358.894531\n",
      "MSE loss: 0.041009\n",
      "Test Error: \n",
      " Avg Loss : 496.242188 \n",
      " MSE loss: 0.075391\n",
      " F1 Score: (0.7218576476527007, 0.23180418220132923, 0.350920245398773, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 174.461670\n",
      "MSE loss: 0.038634\n",
      "Test Error: \n",
      " Avg Loss : 377.384674 \n",
      " MSE loss: 0.076586\n",
      " F1 Score: (0.7516496700659868, 0.20311233587291294, 0.31980602348136805, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: -43.034115\n",
      "MSE loss: 0.032531\n",
      "Test Error: \n",
      " Avg Loss : 268.211426 \n",
      " MSE loss: 0.076230\n",
      " F1 Score: (0.7490283176013326, 0.2186740152374777, 0.3385194479297365, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -141.186142\n",
      "MSE loss: 0.034337\n",
      "Test Error: \n",
      " Avg Loss : 230.013000 \n",
      " MSE loss: 0.075819\n",
      " F1 Score: (0.7739686228936665, 0.21591830118333605, 0.33764258555133086, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -353.120544\n",
      "MSE loss: 0.029662\n",
      "Test Error: \n",
      " Avg Loss : 234.947144 \n",
      " MSE loss: 0.075580\n",
      " F1 Score: (0.7628062360801782, 0.22207813259847625, 0.3440050219711237, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -444.141113\n",
      "MSE loss: 0.029052\n",
      "Test Error: \n",
      " Avg Loss : 290.759155 \n",
      " MSE loss: 0.075617\n",
      " F1 Score: (0.7527412280701754, 0.2225644350786189, 0.34355060678093335, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -545.026489\n",
      "MSE loss: 0.027976\n",
      "Test Error: \n",
      " Avg Loss : 396.048859 \n",
      " MSE loss: 0.074714\n",
      " F1 Score: (0.7340477350219191, 0.2442859458583239, 0.3665774750668937, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -639.311523\n",
      "MSE loss: 0.026237\n",
      "Test Error: \n",
      " Avg Loss : 568.972717 \n",
      " MSE loss: 0.074441\n",
      " F1 Score: (0.7241217798594848, 0.2506078781001783, 0.3723506743737957, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -662.365356\n",
      "MSE loss: 0.024011\n",
      "Test Error: \n",
      " Avg Loss : 713.756104 \n",
      " MSE loss: 0.073564\n",
      " F1 Score: (0.6942924159499609, 0.28789106824444805, 0.40701271914747333, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -668.579773\n",
      "MSE loss: 0.023915\n",
      "Test Error: \n",
      " Avg Loss : 803.820923 \n",
      " MSE loss: 0.072822\n",
      " F1 Score: (0.64008554842652, 0.339601231966283, 0.44376191484854904, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -683.066772\n",
      "MSE loss: 0.023189\n",
      "Test Error: \n",
      " Avg Loss : 984.858093 \n",
      " MSE loss: 0.073943\n",
      " F1 Score: (0.7157894736842105, 0.2645485491976009, 0.386317907444668, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -667.401855\n",
      "MSE loss: 0.024450\n",
      "Test Error: \n",
      " Avg Loss : 965.341064 \n",
      " MSE loss: 0.072480\n",
      " F1 Score: (0.6539080090061112, 0.3295509807100016, 0.4382410002155637, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -703.784424\n",
      "MSE loss: 0.023028\n",
      "Test Error: \n",
      " Avg Loss : 1032.805786 \n",
      " MSE loss: 0.075044\n",
      " F1 Score: (0.5263571990558615, 0.43378181228724266, 0.4756065049320181, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -738.038330\n",
      "MSE loss: 0.022707\n",
      "Test Error: \n",
      " Avg Loss : 1419.181274 \n",
      " MSE loss: 0.083000\n",
      " F1 Score: (0.4792685134890458, 0.4290808883125304, 0.45278823126924395, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 2080.064453\n",
      "MSE loss: 0.634261\n",
      "Test Error: \n",
      " Avg Loss : 1625.291260 \n",
      " MSE loss: 0.113199\n",
      " F1 Score: (0.1484375, 0.02463932566056087, 0.042263311552898655, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1399.358643\n",
      "MSE loss: 0.078110\n",
      "Test Error: \n",
      " Avg Loss : 1398.684937 \n",
      " MSE loss: 0.079416\n",
      " F1 Score: (0.5745519713261649, 0.2598476252228886, 0.35785243888826873, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1178.307739\n",
      "MSE loss: 0.062306\n",
      "Test Error: \n",
      " Avg Loss : 1196.379150 \n",
      " MSE loss: 0.077157\n",
      " F1 Score: (0.5911970656885629, 0.2874047657643054, 0.3867801047120419, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 983.610840\n",
      "MSE loss: 0.069773\n",
      "Test Error: \n",
      " Avg Loss : 1001.472351 \n",
      " MSE loss: 0.075383\n",
      " F1 Score: (0.5840066870994706, 0.33976333279299725, 0.42959622873539655, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 802.384155\n",
      "MSE loss: 0.066963\n",
      "Test Error: \n",
      " Avg Loss : 813.667175 \n",
      " MSE loss: 0.074683\n",
      " F1 Score: (0.5934065934065934, 0.3501377857027071, 0.4404118666530737, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 598.384521\n",
      "MSE loss: 0.059740\n",
      "Test Error: \n",
      " Avg Loss : 636.709778 \n",
      " MSE loss: 0.074568\n",
      " F1 Score: (0.5813008130081301, 0.3708866915221268, 0.4528451261751608, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 428.725891\n",
      "MSE loss: 0.055092\n",
      "Test Error: \n",
      " Avg Loss : 494.210388 \n",
      " MSE loss: 0.074801\n",
      " F1 Score: (0.5901304014318589, 0.3741287080564111, 0.457936507936508, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 172.064621\n",
      "MSE loss: 0.041970\n",
      "Test Error: \n",
      " Avg Loss : 380.570343 \n",
      " MSE loss: 0.075452\n",
      " F1 Score: (0.5780580075662043, 0.3715350948289836, 0.45233866193013617, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: 33.552391\n",
      "MSE loss: 0.039276\n",
      "Test Error: \n",
      " Avg Loss : 248.477615 \n",
      " MSE loss: 0.075745\n",
      " F1 Score: (0.5708624708624709, 0.3969849246231156, 0.46830480925518697, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 900\n",
      "loss: -188.440460\n",
      "MSE loss: 0.030721\n",
      "Test Error: \n",
      " Avg Loss : 235.290421 \n",
      " MSE loss: 0.075802\n",
      " F1 Score: (0.5787420770355924, 0.38482736261954936, 0.462272417486126, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -397.793152\n",
      "MSE loss: 0.025652\n",
      "Test Error: \n",
      " Avg Loss : 282.985535 \n",
      " MSE loss: 0.076792\n",
      " F1 Score: (0.5669694852084789, 0.3945534122224023, 0.46530300133817626, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -531.477783\n",
      "MSE loss: 0.020243\n",
      "Test Error: \n",
      " Avg Loss : 317.364838 \n",
      " MSE loss: 0.078167\n",
      " F1 Score: (0.5661040787623066, 0.3914734965148322, 0.46286535697172976, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -749.105896\n",
      "MSE loss: 0.017869\n",
      "Test Error: \n",
      " Avg Loss : 516.059448 \n",
      " MSE loss: 0.077568\n",
      " F1 Score: (0.5580541532813217, 0.3942292105689739, 0.46204996675216103, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -839.298706\n",
      "MSE loss: 0.018540\n",
      "Test Error: \n",
      " Avg Loss : 833.666626 \n",
      " MSE loss: 0.078491\n",
      " F1 Score: (0.5733366312144447, 0.37574971632355325, 0.45397571484528004, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -832.228638\n",
      "MSE loss: 0.018379\n",
      "Test Error: \n",
      " Avg Loss : 889.848267 \n",
      " MSE loss: 0.079886\n",
      " F1 Score: (0.5725950497575912, 0.36375425514670123, 0.44488501189532115, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -1232.145508\n",
      "MSE loss: 0.011870\n",
      "Test Error: \n",
      " Avg Loss : 1769.503540 \n",
      " MSE loss: 0.079017\n",
      " F1 Score: (0.5612750885478158, 0.385313665099692, 0.45693963860053827, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -1335.752441\n",
      "MSE loss: 0.009286\n",
      "Test Error: \n",
      " Avg Loss : 2426.079346 \n",
      " MSE loss: 0.079047\n",
      " F1 Score: (0.5631114292531615, 0.38255795104555035, 0.4555984555984556, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -1575.489380\n",
      "MSE loss: 0.008462\n",
      "Test Error: \n",
      " Avg Loss : 3302.102539 \n",
      " MSE loss: 0.080009\n",
      " F1 Score: (0.551303122798779, 0.3806127411249797, 0.45032604526275405, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -1560.391235\n",
      "MSE loss: 0.007906\n",
      "Test Error: \n",
      " Avg Loss : 3991.235596 \n",
      " MSE loss: 0.081938\n",
      " F1 Score: (0.5354226440079453, 0.3932566056086886, 0.45345794392523364, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -1700.512451\n",
      "MSE loss: 0.006330\n",
      "Test Error: \n",
      " Avg Loss : 4941.517578 \n",
      " MSE loss: 0.080733\n",
      " F1 Score: (0.5346666666666666, 0.3900145890744043, 0.451026337988565, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1966.737305\n",
      "MSE loss: 0.500591\n",
      "Test Error: \n",
      " Avg Loss : 1636.493042 \n",
      " MSE loss: 0.104746\n",
      " F1 Score: (0.0, 0.0, 0.0, None)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leuch\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 100\n",
      "loss: 1397.565918\n",
      "MSE loss: 0.066814\n",
      "Test Error: \n",
      " Avg Loss : 1393.563721 \n",
      " MSE loss: 0.080472\n",
      " F1 Score: (0.5679666792881485, 0.24315124007132435, 0.340522133938706, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1194.846191\n",
      "MSE loss: 0.082975\n",
      "Test Error: \n",
      " Avg Loss : 1190.466797 \n",
      " MSE loss: 0.078478\n",
      " F1 Score: (0.5654685494223364, 0.28562165667044903, 0.379536887452881, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 1013.297485\n",
      "MSE loss: 0.069729\n",
      "Test Error: \n",
      " Avg Loss : 1007.967102 \n",
      " MSE loss: 0.077270\n",
      " F1 Score: (0.6115702479338843, 0.26390014589074406, 0.3687011663458272, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 796.904236\n",
      "MSE loss: 0.060836\n",
      "Test Error: \n",
      " Avg Loss : 798.995361 \n",
      " MSE loss: 0.076278\n",
      " F1 Score: (0.601219120949631, 0.30377694926244125, 0.4036183502046091, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 625.374512\n",
      "MSE loss: 0.065109\n",
      "Test Error: \n",
      " Avg Loss : 645.813171 \n",
      " MSE loss: 0.075034\n",
      " F1 Score: (0.5935574229691877, 0.3434916518074242, 0.43515761371804085, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 365.662598\n",
      "MSE loss: 0.053543\n",
      "Test Error: \n",
      " Avg Loss : 499.314911 \n",
      " MSE loss: 0.074723\n",
      " F1 Score: (0.6011560693641619, 0.3540282055438483, 0.44562334217506633, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 247.428101\n",
      "MSE loss: 0.052720\n",
      "Test Error: \n",
      " Avg Loss : 385.107330 \n",
      " MSE loss: 0.074847\n",
      " F1 Score: (0.5947295423023579, 0.34754417247527963, 0.43871495805197464, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: 88.696930\n",
      "MSE loss: 0.044666\n",
      "Test Error: \n",
      " Avg Loss : 273.387054 \n",
      " MSE loss: 0.074926\n",
      " F1 Score: (0.6174013252664938, 0.3473820716485654, 0.4446058091286307, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -86.164383\n",
      "MSE loss: 0.041335\n",
      "Test Error: \n",
      " Avg Loss : 227.430130 \n",
      " MSE loss: 0.074883\n",
      " F1 Score: (0.6282394995531725, 0.34187064354028207, 0.44278815872349364, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -250.963165\n",
      "MSE loss: 0.035588\n",
      "Test Error: \n",
      " Avg Loss : 205.329651 \n",
      " MSE loss: 0.074942\n",
      " F1 Score: (0.6279893711248893, 0.3447884584211379, 0.44516534114692335, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -396.444519\n",
      "MSE loss: 0.031092\n",
      "Test Error: \n",
      " Avg Loss : 371.284607 \n",
      " MSE loss: 0.075735\n",
      " F1 Score: (0.631064902331443, 0.32468795590857513, 0.42877020229048485, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -395.046997\n",
      "MSE loss: 0.033020\n",
      "Test Error: \n",
      " Avg Loss : 328.420624 \n",
      " MSE loss: 0.076468\n",
      " F1 Score: (0.6284083703233989, 0.3212838385475766, 0.4251850262790947, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -647.202026\n",
      "MSE loss: 0.025478\n",
      "Test Error: \n",
      " Avg Loss : 601.413391 \n",
      " MSE loss: 0.075545\n",
      " F1 Score: (0.6404385682038052, 0.3219322418544335, 0.4284789644012945, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -679.828735\n",
      "MSE loss: 0.024176\n",
      "Test Error: \n",
      " Avg Loss : 870.333313 \n",
      " MSE loss: 0.076201\n",
      " F1 Score: (0.6410931840632202, 0.315610309612579, 0.4229850097762329, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -727.797363\n",
      "MSE loss: 0.022114\n",
      "Test Error: \n",
      " Avg Loss : 1144.269409 \n",
      " MSE loss: 0.076163\n",
      " F1 Score: (0.6678912564290963, 0.29469930296644514, 0.408952873692498, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -801.514648\n",
      "MSE loss: 0.021304\n",
      "Test Error: \n",
      " Avg Loss : 1402.961060 \n",
      " MSE loss: 0.076755\n",
      " F1 Score: (0.6737756714060031, 0.2765440103744529, 0.3921388346167108, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -923.559814\n",
      "MSE loss: 0.018310\n",
      "Test Error: \n",
      " Avg Loss : 1566.622803 \n",
      " MSE loss: 0.076280\n",
      " F1 Score: (0.650467962562995, 0.29291619387258877, 0.403934279646809, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -1011.068237\n",
      "MSE loss: 0.017120\n",
      "Test Error: \n",
      " Avg Loss : 1672.329346 \n",
      " MSE loss: 0.076824\n",
      " F1 Score: (0.6802469135802469, 0.26795266655859945, 0.38446330968717296, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -1047.575684\n",
      "MSE loss: 0.015756\n",
      "Test Error: \n",
      " Avg Loss : 1852.300293 \n",
      " MSE loss: 0.076752\n",
      " F1 Score: (0.6326877336051648, 0.30183173934187063, 0.4086918349429324, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1638.928833\n",
      "MSE loss: 0.110261\n",
      "Test Error: \n",
      " Avg Loss : 1609.301880 \n",
      " MSE loss: 0.104685\n",
      " F1 Score: (0.011904761904761904, 0.0003242016534284325, 0.0006312135079690706, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1393.277344\n",
      "MSE loss: 0.076417\n",
      "Test Error: \n",
      " Avg Loss : 1398.770874 \n",
      " MSE loss: 0.080905\n",
      " F1 Score: (0.5896289673670094, 0.21381099043605123, 0.31382345943373785, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1181.773315\n",
      "MSE loss: 0.074765\n",
      "Test Error: \n",
      " Avg Loss : 1194.587646 \n",
      " MSE loss: 0.078875\n",
      " F1 Score: (0.5788359788359788, 0.2660074566380288, 0.364504664593514, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 990.760986\n",
      "MSE loss: 0.071741\n",
      "Test Error: \n",
      " Avg Loss : 988.282715 \n",
      " MSE loss: 0.077197\n",
      " F1 Score: (0.5526249048947501, 0.3532177014102772, 0.4309731012658228, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 803.702515\n",
      "MSE loss: 0.069580\n",
      "Test Error: \n",
      " Avg Loss : 813.224976 \n",
      " MSE loss: 0.076280\n",
      " F1 Score: (0.6110738255033556, 0.2951856054465878, 0.3980762924909826, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 631.577515\n",
      "MSE loss: 0.072545\n",
      "Test Error: \n",
      " Avg Loss : 638.706299 \n",
      " MSE loss: 0.075201\n",
      " F1 Score: (0.5997649133117837, 0.33084778732371534, 0.4264521521103218, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 456.021729\n",
      "MSE loss: 0.060085\n",
      "Test Error: \n",
      " Avg Loss : 515.959229 \n",
      " MSE loss: 0.074761\n",
      " F1 Score: (0.6048780487804878, 0.3417085427135678, 0.43671017194945094, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 329.479492\n",
      "MSE loss: 0.061801\n",
      "Test Error: \n",
      " Avg Loss : 349.017151 \n",
      " MSE loss: 0.074453\n",
      " F1 Score: (0.6034968979131415, 0.34689576916842274, 0.4405558414822439, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: 58.809143\n",
      "MSE loss: 0.046486\n",
      "Test Error: \n",
      " Avg Loss : 284.731293 \n",
      " MSE loss: 0.074527\n",
      " F1 Score: (0.6455176767676768, 0.33149619063057223, 0.43804219770804326, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: -121.981316\n",
      "MSE loss: 0.039704\n",
      "Test Error: \n",
      " Avg Loss : 199.453537 \n",
      " MSE loss: 0.074001\n",
      " F1 Score: (0.6326712125704121, 0.34592316420813746, 0.44728568434290505, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -131.806519\n",
      "MSE loss: 0.042143\n",
      "Test Error: \n",
      " Avg Loss : 204.132385 \n",
      " MSE loss: 0.074100\n",
      " F1 Score: (0.640251572327044, 0.33003728319014425, 0.4355546047705637, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -313.455505\n",
      "MSE loss: 0.037501\n",
      "Test Error: \n",
      " Avg Loss : 237.577881 \n",
      " MSE loss: 0.074523\n",
      " F1 Score: (0.6553745928338762, 0.32614686334900306, 0.4355449723996103, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -422.186462\n",
      "MSE loss: 0.033782\n",
      "Test Error: \n",
      " Avg Loss : 359.346832 \n",
      " MSE loss: 0.075501\n",
      " F1 Score: (0.684085510688836, 0.28011022856216566, 0.3974698102357677, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -502.444153\n",
      "MSE loss: 0.030176\n",
      "Test Error: \n",
      " Avg Loss : 419.887085 \n",
      " MSE loss: 0.076580\n",
      " F1 Score: (0.6520763187429854, 0.28254174096287893, 0.39425469350825604, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -490.530396\n",
      "MSE loss: 0.030386\n",
      "Test Error: \n",
      " Avg Loss : 666.087036 \n",
      " MSE loss: 0.075872\n",
      " F1 Score: (0.66234247590808, 0.2896741773383044, 0.40306755385135895, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -682.371582\n",
      "MSE loss: 0.026066\n",
      "Test Error: \n",
      " Avg Loss : 757.379700 \n",
      " MSE loss: 0.075922\n",
      " F1 Score: (0.6629001883239172, 0.2852974550170206, 0.3989120580235721, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -579.532593\n",
      "MSE loss: 0.027597\n",
      "Test Error: \n",
      " Avg Loss : 905.706848 \n",
      " MSE loss: 0.076153\n",
      " F1 Score: (0.689332766680833, 0.2629275409304587, 0.38066181647500585, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -627.092407\n",
      "MSE loss: 0.026229\n",
      "Test Error: \n",
      " Avg Loss : 1018.489990 \n",
      " MSE loss: 0.075668\n",
      " F1 Score: (0.6851633215269579, 0.2822175393094505, 0.3997703788748565, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -715.349731\n",
      "MSE loss: 0.022943\n",
      "Test Error: \n",
      " Avg Loss : 1085.155640 \n",
      " MSE loss: 0.075496\n",
      " F1 Score: (0.6468694096601073, 0.29307829469930297, 0.4033913431503793, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -747.343506\n",
      "MSE loss: 0.021806\n",
      "Test Error: \n",
      " Avg Loss : 1168.004639 \n",
      " MSE loss: 0.075695\n",
      " F1 Score: (0.6817644742024419, 0.2805965310423083, 0.39756545705098756, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1808.896606\n",
      "MSE loss: 0.312042\n",
      "Test Error: \n",
      " Avg Loss : 1656.674927 \n",
      " MSE loss: 0.132159\n",
      " F1 Score: (0.09469850263051396, 0.0379315934511266, 0.05416666666666667, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1386.457275\n",
      "MSE loss: 0.070021\n",
      "Test Error: \n",
      " Avg Loss : 1417.382202 \n",
      " MSE loss: 0.081231\n",
      " F1 Score: (0.553565030455034, 0.2504457772734641, 0.3448660714285714, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1203.646973\n",
      "MSE loss: 0.081518\n",
      "Test Error: \n",
      " Avg Loss : 1200.624878 \n",
      " MSE loss: 0.078782\n",
      " F1 Score: (0.589173155357805, 0.2575782136488896, 0.35844800360929396, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 937.713867\n",
      "MSE loss: 0.072402\n",
      "Test Error: \n",
      " Avg Loss : 1010.216248 \n",
      " MSE loss: 0.077737\n",
      " F1 Score: (0.5941284403669724, 0.2624412384503161, 0.36406566224420955, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 820.800659\n",
      "MSE loss: 0.069032\n",
      "Test Error: \n",
      " Avg Loss : 855.108337 \n",
      " MSE loss: 0.077071\n",
      " F1 Score: (0.5748806682577565, 0.3123682930782947, 0.4047894128767987, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 619.197876\n",
      "MSE loss: 0.069279\n",
      "Test Error: \n",
      " Avg Loss : 624.934021 \n",
      " MSE loss: 0.074977\n",
      " F1 Score: (0.5913516609392898, 0.3347382071648565, 0.4274919780561019, None)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 600\n",
      "loss: 438.323425\n",
      "MSE loss: 0.061390\n",
      "Test Error: \n",
      " Avg Loss : 490.466003 \n",
      " MSE loss: 0.074814\n",
      " F1 Score: (0.6104972375690608, 0.3224185443345761, 0.4219794208125597, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 307.642456\n",
      "MSE loss: 0.062523\n",
      "Test Error: \n",
      " Avg Loss : 363.479645 \n",
      " MSE loss: 0.074454\n",
      " F1 Score: (0.6158998252766453, 0.34284324850056735, 0.44048734770384257, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: 162.183380\n",
      "MSE loss: 0.060154\n",
      "Test Error: \n",
      " Avg Loss : 289.770782 \n",
      " MSE loss: 0.074419\n",
      " F1 Score: (0.6256814052089643, 0.3349003079915708, 0.4362791679864851, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: 6.335465\n",
      "MSE loss: 0.050483\n",
      "Test Error: \n",
      " Avg Loss : 222.893158 \n",
      " MSE loss: 0.074051\n",
      " F1 Score: (0.6298780487804878, 0.3349003079915708, 0.4372949518467563, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: -169.191193\n",
      "MSE loss: 0.041891\n",
      "Test Error: \n",
      " Avg Loss : 200.170700 \n",
      " MSE loss: 0.073928\n",
      " F1 Score: (0.6424546023794615, 0.3326308964175717, 0.43832105094520984, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -227.051941\n",
      "MSE loss: 0.039853\n",
      "Test Error: \n",
      " Avg Loss : 246.960968 \n",
      " MSE loss: 0.074872\n",
      " F1 Score: (0.6368785399622404, 0.3280920732695737, 0.43308013266288653, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -278.653137\n",
      "MSE loss: 0.040851\n",
      "Test Error: \n",
      " Avg Loss : 327.984863 \n",
      " MSE loss: 0.074570\n",
      " F1 Score: (0.6481417158735672, 0.3024801426487275, 0.41246684350132623, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -341.389282\n",
      "MSE loss: 0.035612\n",
      "Test Error: \n",
      " Avg Loss : 379.564453 \n",
      " MSE loss: 0.076375\n",
      " F1 Score: (0.6713947990543735, 0.2762198087210245, 0.3914092109796715, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -381.562500\n",
      "MSE loss: 0.034837\n",
      "Test Error: \n",
      " Avg Loss : 561.477600 \n",
      " MSE loss: 0.075511\n",
      " F1 Score: (0.6756206756206756, 0.269087372345599, 0.38488291212613035, None)\n",
      "\n",
      "Epoch : 1500\n",
      "loss: -439.868286\n",
      "MSE loss: 0.032864\n",
      "Test Error: \n",
      " Avg Loss : 639.160950 \n",
      " MSE loss: 0.075364\n",
      " F1 Score: (0.6701030927835051, 0.2844869508834495, 0.3994082840236687, None)\n",
      "\n",
      "Epoch : 1600\n",
      "loss: -245.971893\n",
      "MSE loss: 0.037488\n",
      "Test Error: \n",
      " Avg Loss : 647.357544 \n",
      " MSE loss: 0.075725\n",
      " F1 Score: (0.635427052176803, 0.30993678067758146, 0.41664850730006536, None)\n",
      "\n",
      "Epoch : 1700\n",
      "loss: -686.310181\n",
      "MSE loss: 0.024377\n",
      "Test Error: \n",
      " Avg Loss : 697.075317 \n",
      " MSE loss: 0.075208\n",
      " F1 Score: (0.6563876651982379, 0.28983627816501867, 0.4021140222647026, None)\n",
      "\n",
      "Epoch : 1800\n",
      "loss: -583.362244\n",
      "MSE loss: 0.027384\n",
      "Test Error: \n",
      " Avg Loss : 798.570862 \n",
      " MSE loss: 0.076641\n",
      " F1 Score: (0.6878612716763006, 0.23147998054790078, 0.3463917525773196, None)\n",
      "\n",
      "Epoch : 1900\n",
      "loss: -633.355469\n",
      "MSE loss: 0.028141\n",
      "Test Error: \n",
      " Avg Loss : 790.616882 \n",
      " MSE loss: 0.074731\n",
      " F1 Score: (0.6323381415632339, 0.3055600583562976, 0.41202185792349727, None)\n",
      "\n",
      "Epoch : 0\n",
      "loss: 1735.974976\n",
      "MSE loss: 0.226565\n",
      "Test Error: \n",
      " Avg Loss : 1624.530640 \n",
      " MSE loss: 0.100597\n",
      " F1 Score: (0.53, 0.00859134381585346, 0.016908597862498004, None)\n",
      "\n",
      "Epoch : 100\n",
      "loss: 1417.888306\n",
      "MSE loss: 0.095022\n",
      "Test Error: \n",
      " Avg Loss : 1403.183716 \n",
      " MSE loss: 0.082069\n",
      " F1 Score: (0.5886984715145901, 0.20603015075376885, 0.3052353506243996, None)\n",
      "\n",
      "Epoch : 200\n",
      "loss: 1178.013062\n",
      "MSE loss: 0.070395\n",
      "Test Error: \n",
      " Avg Loss : 1203.811279 \n",
      " MSE loss: 0.080963\n",
      " F1 Score: (0.5634272997032641, 0.24623115577889448, 0.3426959954878736, None)\n",
      "\n",
      "Epoch : 300\n",
      "loss: 990.776489\n",
      "MSE loss: 0.080844\n",
      "Test Error: \n",
      " Avg Loss : 981.960938 \n",
      " MSE loss: 0.080901\n",
      " F1 Score: (0.5378343118069145, 0.26730426325174256, 0.35711965349214947, None)\n",
      "\n",
      "Epoch : 400\n",
      "loss: 812.749023\n",
      "MSE loss: 0.076533\n",
      "Test Error: \n",
      " Avg Loss : 820.331726 \n",
      " MSE loss: 0.080268\n",
      " F1 Score: (0.5534173855341739, 0.2703841789593127, 0.36327997386475, None)\n",
      "\n",
      "Epoch : 500\n",
      "loss: 658.591064\n",
      "MSE loss: 0.078345\n",
      "Test Error: \n",
      " Avg Loss : 659.400940 \n",
      " MSE loss: 0.080027\n",
      " F1 Score: (0.5474263515700875, 0.27411249797373965, 0.36530568157269383, None)\n",
      "\n",
      "Epoch : 600\n",
      "loss: 482.705627\n",
      "MSE loss: 0.071591\n",
      "Test Error: \n",
      " Avg Loss : 515.133362 \n",
      " MSE loss: 0.078198\n",
      " F1 Score: (0.5677577240746405, 0.30085913438158535, 0.3933036660309387, None)\n",
      "\n",
      "Epoch : 700\n",
      "loss: 339.749939\n",
      "MSE loss: 0.067670\n",
      "Test Error: \n",
      " Avg Loss : 378.706177 \n",
      " MSE loss: 0.076728\n",
      " F1 Score: (0.5608072225172597, 0.3423569460204247, 0.42516356316054355, None)\n",
      "\n",
      "Epoch : 800\n",
      "loss: 197.578430\n",
      "MSE loss: 0.061355\n",
      "Test Error: \n",
      " Avg Loss : 290.726349 \n",
      " MSE loss: 0.076412\n",
      " F1 Score: (0.579407616361072, 0.33295509807100016, 0.42289479102326544, None)\n",
      "\n",
      "Epoch : 900\n",
      "loss: 101.928009\n",
      "MSE loss: 0.056433\n",
      "Test Error: \n",
      " Avg Loss : 195.394333 \n",
      " MSE loss: 0.076251\n",
      " F1 Score: (0.5650557620817844, 0.3449505592478522, 0.42838449924509314, None)\n",
      "\n",
      "Epoch : 1000\n",
      "loss: 18.888033\n",
      "MSE loss: 0.057645\n",
      "Test Error: \n",
      " Avg Loss : 273.577271 \n",
      " MSE loss: 0.076018\n",
      " F1 Score: (0.5722321656865252, 0.36278165018641595, 0.4440476190476191, None)\n",
      "\n",
      "Epoch : 1100\n",
      "loss: -92.584381\n",
      "MSE loss: 0.049680\n",
      "Test Error: \n",
      " Avg Loss : 281.564667 \n",
      " MSE loss: 0.076856\n",
      " F1 Score: (0.5770543449724337, 0.3562976171178473, 0.4405692523551814, None)\n",
      "\n",
      "Epoch : 1200\n",
      "loss: -213.459778\n",
      "MSE loss: 0.040943\n",
      "Test Error: \n",
      " Avg Loss : 334.303223 \n",
      " MSE loss: 0.077939\n",
      " F1 Score: (0.562823994075537, 0.36958988490841305, 0.44618395303326813, None)\n",
      "\n",
      "Epoch : 1300\n",
      "loss: -299.652527\n",
      "MSE loss: 0.037905\n",
      "Test Error: \n",
      " Avg Loss : 489.409943 \n",
      " MSE loss: 0.079253\n",
      " F1 Score: (0.5443510737628384, 0.37801912789755227, 0.4461876973117765, None)\n",
      "\n",
      "Epoch : 1400\n",
      "loss: -505.151062\n",
      "MSE loss: 0.028484\n",
      "Test Error: \n",
      " Avg Loss : 715.619995 \n",
      " MSE loss: 0.080555\n",
      " F1 Score: (0.5368938861560084, 0.3715350948289836, 0.43916459091780036, None)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "highest_f1_score = [0,0,0,0]\n",
    "mask_magnitude = 1.3\n",
    "#Search \n",
    "\n",
    "for l2_weight in [0., 0.1, 0.2, 0.3]:\n",
    "    for dropout_rate in [0., 0.1, 0.2, 0.3]:\n",
    "        print(\"using hyperparameters : \" + str( l2_weight) + \" , \" + str(dropout_rate))\n",
    "        train_dataset = MovielensDataset(user_ratings[:843], mask_magnitude)\n",
    "        test_dataset = MovielensDataset(user_ratings[843:], mask_magnitude)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "\n",
    "        losses = []\n",
    "        mse_losses = []    \n",
    "        test_losses = []\n",
    "        test_mse_losses = []\n",
    "\n",
    "        model = VariationalAutoEncoder(dropout_rate = dropout_rate).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4, weight_decay = l2_weight)\n",
    "        mse_loss_fcn = nn.MSELoss()\n",
    "\n",
    "        for t in range(epochs):\n",
    "            train(train_dataloader, model,  optimizer, t)\n",
    "            test(test_dataloader, model, t )\n",
    "            if t % 100 == 0:\n",
    "                print(\" F1 Score: \" + str(model.f1) + \"\\n\")\n",
    "                if model.f1[2] > highest_f1_score[2]:\n",
    "                    highest_f1_score = model.f1\n",
    "                    torch.save(model.state_dict(), \"./models/best.pth\")\n",
    "                    print(\"New best using hyper parameters : \" + str(mask_magnitude) + \" ,\" + str(l2_weight) + \" ,\" + str(dropout_rate)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fb6853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e486d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
